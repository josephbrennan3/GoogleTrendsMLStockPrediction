{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>education</th>\n",
       "      <th>Edexcel</th>\n",
       "      <th>publisher</th>\n",
       "      <th>penguin</th>\n",
       "      <th>books</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-03</th>\n",
       "      <td>698.932507</td>\n",
       "      <td>704.052891</td>\n",
       "      <td>695.518917</td>\n",
       "      <td>696.372314</td>\n",
       "      <td>2289306</td>\n",
       "      <td>58</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>67</td>\n",
       "      <td>61</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>697.225697</td>\n",
       "      <td>698.688411</td>\n",
       "      <td>684.424736</td>\n",
       "      <td>686.131531</td>\n",
       "      <td>3337718</td>\n",
       "      <td>71</td>\n",
       "      <td>76</td>\n",
       "      <td>83</td>\n",
       "      <td>89</td>\n",
       "      <td>65</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-05</th>\n",
       "      <td>687.838354</td>\n",
       "      <td>695.945629</td>\n",
       "      <td>686.558257</td>\n",
       "      <td>693.385437</td>\n",
       "      <td>3200061</td>\n",
       "      <td>76</td>\n",
       "      <td>79</td>\n",
       "      <td>85</td>\n",
       "      <td>86</td>\n",
       "      <td>67</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-06</th>\n",
       "      <td>692.958673</td>\n",
       "      <td>695.518866</td>\n",
       "      <td>689.545084</td>\n",
       "      <td>694.238770</td>\n",
       "      <td>1244707</td>\n",
       "      <td>66</td>\n",
       "      <td>70</td>\n",
       "      <td>74</td>\n",
       "      <td>71</td>\n",
       "      <td>73</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-09</th>\n",
       "      <td>695.945545</td>\n",
       "      <td>701.065929</td>\n",
       "      <td>694.347144</td>\n",
       "      <td>698.505737</td>\n",
       "      <td>1714753</td>\n",
       "      <td>80</td>\n",
       "      <td>87</td>\n",
       "      <td>99</td>\n",
       "      <td>79</td>\n",
       "      <td>64</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Volume  Pearson  \\\n",
       "Date                                                                           \n",
       "2017-01-03  698.932507  704.052891  695.518917  696.372314  2289306       58   \n",
       "2017-01-04  697.225697  698.688411  684.424736  686.131531  3337718       71   \n",
       "2017-01-05  687.838354  695.945629  686.558257  693.385437  3200061       76   \n",
       "2017-01-06  692.958673  695.518866  689.545084  694.238770  1244707       66   \n",
       "2017-01-09  695.945545  701.065929  694.347144  698.505737  1714753       80   \n",
       "\n",
       "            education  Edexcel  publisher  penguin  books  \n",
       "Date                                                       \n",
       "2017-01-03         72       72         67       61     99  \n",
       "2017-01-04         76       83         89       65    100  \n",
       "2017-01-05         79       85         86       67     99  \n",
       "2017-01-06         70       74         71       73     92  \n",
       "2017-01-09         87       99         79       64     96  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/josephbrennan/Desktop/Data/Merged/pson_merged.csv')\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "df['Date'] = pd.to_datetime(df.Date)\n",
    "df.index = pd.DatetimeIndex(df.Date)\n",
    "df.drop('Date', axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open         0\n",
       "High         0\n",
       "Low          0\n",
       "Close        0\n",
       "Volume       0\n",
       "Pearson      0\n",
       "education    0\n",
       "Edexcel      0\n",
       "publisher    0\n",
       "penguin      0\n",
       "books        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>education</th>\n",
       "      <th>Edexcel</th>\n",
       "      <th>publisher</th>\n",
       "      <th>penguin</th>\n",
       "      <th>books</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-06-29</th>\n",
       "      <td>834.400024</td>\n",
       "      <td>839.400024</td>\n",
       "      <td>823.400024</td>\n",
       "      <td>830.799988</td>\n",
       "      <td>1882235</td>\n",
       "      <td>83</td>\n",
       "      <td>91</td>\n",
       "      <td>60</td>\n",
       "      <td>87</td>\n",
       "      <td>80</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Volume  Pearson  \\\n",
       "Date                                                                           \n",
       "2021-06-29  834.400024  839.400024  823.400024  830.799988  1882235       83   \n",
       "\n",
       "            education  Edexcel  publisher  penguin  books  \n",
       "Date                                                       \n",
       "2021-06-29         91       60         87       80     94  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Last row of data used to predict\n",
    "compare_price = df.tail(1)\n",
    "compare_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>education</th>\n",
       "      <th>Edexcel</th>\n",
       "      <th>publisher</th>\n",
       "      <th>penguin</th>\n",
       "      <th>books</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-03</th>\n",
       "      <td>698.932507</td>\n",
       "      <td>704.052891</td>\n",
       "      <td>695.518917</td>\n",
       "      <td>696.372314</td>\n",
       "      <td>2289306</td>\n",
       "      <td>58</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>67</td>\n",
       "      <td>61</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>697.225697</td>\n",
       "      <td>698.688411</td>\n",
       "      <td>684.424736</td>\n",
       "      <td>686.131531</td>\n",
       "      <td>3337718</td>\n",
       "      <td>71</td>\n",
       "      <td>76</td>\n",
       "      <td>83</td>\n",
       "      <td>89</td>\n",
       "      <td>65</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-05</th>\n",
       "      <td>687.838354</td>\n",
       "      <td>695.945629</td>\n",
       "      <td>686.558257</td>\n",
       "      <td>693.385437</td>\n",
       "      <td>3200061</td>\n",
       "      <td>76</td>\n",
       "      <td>79</td>\n",
       "      <td>85</td>\n",
       "      <td>86</td>\n",
       "      <td>67</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-06</th>\n",
       "      <td>692.958673</td>\n",
       "      <td>695.518866</td>\n",
       "      <td>689.545084</td>\n",
       "      <td>694.238770</td>\n",
       "      <td>1244707</td>\n",
       "      <td>66</td>\n",
       "      <td>70</td>\n",
       "      <td>74</td>\n",
       "      <td>71</td>\n",
       "      <td>73</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-09</th>\n",
       "      <td>695.945545</td>\n",
       "      <td>701.065929</td>\n",
       "      <td>694.347144</td>\n",
       "      <td>698.505737</td>\n",
       "      <td>1714753</td>\n",
       "      <td>80</td>\n",
       "      <td>87</td>\n",
       "      <td>99</td>\n",
       "      <td>79</td>\n",
       "      <td>64</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-22</th>\n",
       "      <td>855.000000</td>\n",
       "      <td>859.799988</td>\n",
       "      <td>850.200012</td>\n",
       "      <td>853.400024</td>\n",
       "      <td>942490</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>100</td>\n",
       "      <td>97</td>\n",
       "      <td>82</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-23</th>\n",
       "      <td>853.400024</td>\n",
       "      <td>856.599976</td>\n",
       "      <td>844.400024</td>\n",
       "      <td>845.400024</td>\n",
       "      <td>931856</td>\n",
       "      <td>79</td>\n",
       "      <td>92</td>\n",
       "      <td>53</td>\n",
       "      <td>76</td>\n",
       "      <td>82</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-24</th>\n",
       "      <td>849.599976</td>\n",
       "      <td>853.400024</td>\n",
       "      <td>832.200012</td>\n",
       "      <td>835.000000</td>\n",
       "      <td>1166885</td>\n",
       "      <td>79</td>\n",
       "      <td>100</td>\n",
       "      <td>72</td>\n",
       "      <td>96</td>\n",
       "      <td>79</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-25</th>\n",
       "      <td>838.000000</td>\n",
       "      <td>840.200012</td>\n",
       "      <td>832.400024</td>\n",
       "      <td>838.000000</td>\n",
       "      <td>858309</td>\n",
       "      <td>76</td>\n",
       "      <td>89</td>\n",
       "      <td>44</td>\n",
       "      <td>65</td>\n",
       "      <td>86</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-28</th>\n",
       "      <td>834.599976</td>\n",
       "      <td>838.599976</td>\n",
       "      <td>832.703979</td>\n",
       "      <td>833.400024</td>\n",
       "      <td>629863</td>\n",
       "      <td>86</td>\n",
       "      <td>93</td>\n",
       "      <td>64</td>\n",
       "      <td>73</td>\n",
       "      <td>80</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1134 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Volume  Pearson  \\\n",
       "Date                                                                           \n",
       "2017-01-03  698.932507  704.052891  695.518917  696.372314  2289306       58   \n",
       "2017-01-04  697.225697  698.688411  684.424736  686.131531  3337718       71   \n",
       "2017-01-05  687.838354  695.945629  686.558257  693.385437  3200061       76   \n",
       "2017-01-06  692.958673  695.518866  689.545084  694.238770  1244707       66   \n",
       "2017-01-09  695.945545  701.065929  694.347144  698.505737  1714753       80   \n",
       "...                ...         ...         ...         ...      ...      ...   \n",
       "2021-06-22  855.000000  859.799988  850.200012  853.400024   942490       96   \n",
       "2021-06-23  853.400024  856.599976  844.400024  845.400024   931856       79   \n",
       "2021-06-24  849.599976  853.400024  832.200012  835.000000  1166885       79   \n",
       "2021-06-25  838.000000  840.200012  832.400024  838.000000   858309       76   \n",
       "2021-06-28  834.599976  838.599976  832.703979  833.400024   629863       86   \n",
       "\n",
       "            education  Edexcel  publisher  penguin  books  \n",
       "Date                                                       \n",
       "2017-01-03         72       72         67       61     99  \n",
       "2017-01-04         76       83         89       65    100  \n",
       "2017-01-05         79       85         86       67     99  \n",
       "2017-01-06         70       74         71       73     92  \n",
       "2017-01-09         87       99         79       64     96  \n",
       "...               ...      ...        ...      ...    ...  \n",
       "2021-06-22         96      100         97       82     95  \n",
       "2021-06-23         92       53         76       82     92  \n",
       "2021-06-24        100       72         96       79     93  \n",
       "2021-06-25         89       44         65       86     93  \n",
       "2021-06-28         93       64         73       80     96  \n",
       "\n",
       "[1134 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get all data except last row (actual_price)\n",
    "df = df.head(len(df)-1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Open',\n",
       " 'High',\n",
       " 'Low',\n",
       " 'Volume',\n",
       " 'Pearson',\n",
       " 'education',\n",
       " 'Edexcel',\n",
       " 'publisher',\n",
       " 'penguin',\n",
       " 'books']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save Feature Columns\n",
    "feature_list = list(df.columns)\n",
    "feature_list.remove('Close')\n",
    "feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from pprint import pprint\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features (X) and Labels (y)\n",
    "y = df.iloc[:, 3].values\n",
    "X = df.iloc[:, [0, 1, 2, 4, 5, 6, 7, 8, 9, 10]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = np.array(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size = 0.3, random_state = 100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(793, 10)\n",
      "(341, 10)\n",
      "(793,)\n",
      "(341,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestRegressor(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 2000,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 90,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average Error: 3.0395 degrees.\n",
      "Accuracy = 99.49%.\n",
      "Model Performance\n",
      "Average Error: 12.1799 degrees.\n",
      "Accuracy = 97.61%.\n",
      "Improvement of -1.89%.\n"
     ]
    }
   ],
   "source": [
    "#Model Evaluation Scores\n",
    "from sklearn import metrics\n",
    "\n",
    "def evaluate(model, X_test, y_test):\n",
    "    predictions = model.predict(X_test)\n",
    "    errors = abs(predictions - y_test)\n",
    "    mape = 100 * np.mean(errors / y_test)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    return accuracy\n",
    "\n",
    "base_model = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "base_model.fit(X_test, y_test)\n",
    "base_accuracy = evaluate(base_model, X_test, y_test)\n",
    "\n",
    "best_random = rf_random.best_estimator_\n",
    "random_accuracy = evaluate(best_random, X_test, y_test)\n",
    "\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (random_accuracy - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "regressor = RandomForestRegressor(n_estimators = 1000, min_samples_split=2, min_samples_leaf=1, bootstrap=True, max_depth=100, max_features='auto')\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9720921038666716\n",
      "Mean Absolute Error: 12.382351587200443\n",
      "Mean Squared Error: 494.0754505463822\n",
      "Root Mean Squared Error: 22.227808046372505\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.r2_score(y_test, y_pred))\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared score:  0.9720921038666716\n",
      "Mean Absolute Error: 12.382351587200443\n",
      "Mean Squared Error: 494.0754505463822\n",
      "Root Mean Squared Error: 22.227808046372505\n",
      "Mean Absolute Percentage Error (MAPE): 2.43\n",
      "Accuracy: 97.57\n"
     ]
    }
   ],
   "source": [
    "#Model Evaluation Scores\n",
    "from sklearn import metrics\n",
    "\n",
    "print('R-squared score: ', regressor.score(X_test, y_test))\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "mape = np.mean(np.abs((y_test - y_pred) / np.abs(y_test)))\n",
    "print('Mean Absolute Percentage Error (MAPE):', round(mape * 100, 2))\n",
    "print('Accuracy:', round(100*(1 - mape), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1134,)\n",
      "(341,)\n",
      "(793,)\n",
      "546.73974609375\n",
      "833.6268794555664\n",
      "833.6268794555664\n"
     ]
    }
   ],
   "source": [
    "print(df.index.shape)\n",
    "print(y_pred.shape)\n",
    "print(y_train.shape)\n",
    "predictions = np.concatenate((y_train, y_pred))\n",
    "print(y_train[-1])\n",
    "print(y_pred[-1])\n",
    "print(predictions[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda (base)",
   "language": "python",
   "name": "anaconda-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
